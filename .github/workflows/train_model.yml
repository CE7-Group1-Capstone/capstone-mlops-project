# Train the ML Model for the first time or whenever
# there is code refactoring but no data changes.
name: ML Model Training

on:
  #pull_request:
  #  branches: [ "main" ]
  #  paths:
  #    - 'main.py'
  #    - 'config.yml'
  #    - 'steps/*.py'
  #    - 'requirements.txt'
  workflow_dispatch:

env:
  ML_ARTEFACTS_S3: s3://ce7-grp-1-proj/DVC_artefacts/
  ML_NEW_DATA_S3: s3://ce7-grp-1-proj/new_ML_data/

jobs:
  Train:
    name: Train or Retrain ML Model
    runs-on: ubuntu-latest
    environment: development

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12" # Specify the required Python version

      - name: Create Python ML venv
        run: | 
          python3 -m venv venv
          echo "PATH=$(pwd)/venv/bin:$PATH" >> $GITHUB_ENV

      - name: Install packages and dependencies
        run: | # inclusive of dvc[s3] install
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

    # To intialise dvc tracking if and only if it has not been set up for
    # the first-time already
      - name: First-time initialise DVC only
        run: |
          ! test -d ".dvc" && make setup_dvc
        continue-on-error: true

    # Last-committed datasets are saved in S3 'dvc_artefacts' folder for download
      - name: Pull from DVC
        run: dvc pull --allow-missing data/train.csv data/test.csv
        continue-on-error: true

    # Latest new datasets are placed in S3 'new_datasets' folder,
    # if new datasets exist then overide the dvc-pulled datasets
      - name: Pull datasets from S3
        run: aws s3 cp ${{ env.ML_NEW_DATA_S3 }} data/ --quiet --recursive

      - name: Train the prediction model
        run: make train

      - name: Test the trained model
        run: make test

      - name: Fetch all tags to get the latest
        id: get_latest_tag
        run: |
          git fetch --tags
          echo "LATEST_TAG=$(git describe --tags `git rev-list --tags --max-count=1`)" >> "$GITHUB_OUTPUT"
          echo "LATEST_TAG=$(git describe --tags `git rev-list --tags --max-count=1`)"

      - name: Version ML and Git artefacts
        run: |
          dvc add data/train.csv
          dvc add data/test.csv
          git add data/train.csv.dvc data/.gitignore
          git add data/test.csv.dvc data/.gitignore
          git commit -m "update training and testing data ${{ steps.get_latest_tag.outputs.LATEST_TAG }}"
          dvc add models/model.pkl
          git add models/model.pkl.dvc models/.gitignore
          git commit -m "update trained model ${{ steps.get_latest_tag.outputs.LATEST_TAG }}"
          dvc remote add -d remote ${{ env.ML_ARTEFACTS_S3 }}
          git commit .dvc/config -m "configure dvc remote storage"
          dvc push
          git push origin main

      - name: Clean up the training environment
        run: make clean
#-------------------------------------------------------------------------
# Keep in storage:
# a) dvc remote modify --local remote credentialpath ~/.aws/credentials
#-------------------------------------------------------------------------
