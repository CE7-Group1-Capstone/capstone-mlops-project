# Train the ML Model for the first time or whenever
# there is code refactoring but no data changes.
name: Train ML Model

on:
  #pull_request:
  #  branches: [ "main" ]
  #  paths:
  #    - 'main.py'
  #    - 'config.yml'
  #    - 'steps/*.py'
  #    - 'requirements.txt'
  workflow_dispatch:

env:
  ML_ARTEFACTS_S3: s3://ce7-grp-1-project/DVC_artefacts/
  ML_DATASETS_S3: s3://ce7-grp-1-project/new_ML_data/
  VER_TAG: ${{ github.sha }}

jobs:
  Train:
    name: Train or Retrain ML Model
    runs-on: ubuntu-latest
    environment: development

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12" # Specify the required Python version

      - name: Create Python ML venv
        run: | 
          python3 -m venv venv
          echo "PATH=$(pwd)/venv/bin:$PATH" >> $GITHUB_ENV

      - name: Install packages and dependencies
        run: | # inclusive of dvc[s3] install
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

    # Last-committed datasets are saved in S3 'dvc_artefacts' folder for download
      - name: Pull from DVC
        run: dvc pull --allow-missing data/train.csv data/test.csv

    # Latest new datasets are placed in S3 'new_datasets' folder,
    # if new datasets exist then overide the dvc-pulled datasets
      - name: Pull datasets from S3
        run: aws s3 cp ${{ env.ML_DATASETS_S3 }} data/ --quiet --recursive

      - name: Train the prediction model
        run: make run

      - name: Test the trained model
        run: make test

      - name: Version ML and Git artefacts
        run: |
          dvc add data/train.csv
          dvc add data/test.csv
          git add data/train.csv.dvc data/.gitignore
          git add data/test.csv.dvc data/.gitignore
          git commit -m "add training and testing data ${{ env.VER_TAG }}"
          dvc add models/model.pkl
          git add models/model.pkl.dvc models/.gitignore
          git commit -m "add trained model ${{ env.VER_TAG }}"
          dvc remote add -d remote ${{ env.ML_ARTEFACTS_S3 }}
          dvc push
          git push origin main
          git add .

      - name: Commit & push Git changes
        uses: actions-js/push@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Clean up the training environment
        run: make clean
#-------------------------------------------------------------------------
# Keep in storage:
# a) dvc remote modify --local remote credentialpath ~/.aws/credentials
#-------------------------------------------------------------------------
